[![header](https://capsule-render.vercel.app/api?type=rect&height=150&color=gradient&text=COVER%20-%20Vector%20Contrastive%20Learning&fontAlign=50&reversal=true&textBg=false&fontAlignY=40&fontSize=40&desc=For%20Pixel-Wise%20Pretraining%20In%20Medical%20Vision&descSize=39&descAlign=50&descAlignY=70)](https://arxiv.org/abs/2506.20850)
---
[![Paper](https://img.shields.io/badge/CVPR-Conference-purple)](https://arxiv.org/abs/2506.20850)

COVER is a groundbreaking framework to contrastive learning by modeling pixel-wise feature dispersion in a novel vector regression-based paradigm (Vector CL). By aligning semantic correspondences as displacement vectors, it enables precise, scalable, and annotation-free self-supervised pretrainingâ€”paving the way for more powerful and granular medical vision foundation models.

<p align="center"><img width="80%" src="fig/fig.png" /></p>

> [**Vector Contrastive Learning For Pixel-Wise Pretraining In Medical Vision**](https://arxiv.org/abs/2506.20850),  
> [Yuting He](https://yutinghe-list.github.io/), [Shuo Li](https://scholar.google.com/citations?user=6WNtJa0AAAAJ&hl=en)* 
> In: Proc. International Conference on Computer Vision (ICCV), 2025,
> *arXiv preprint ([arXiv 2506.20850](https://arxiv.org/abs/2506.20850))*   
