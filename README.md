[![header](https://capsule-render.vercel.app/api?type=rect&height=120&color=gradient&text=COVER%20-%20Vector%20Contrastive%20Learning&fontAlign=50&reversal=true&textBg=false&fontAlignY=37&fontSize=40&desc=For%20Pixel-Wise%20Pretraining%20In%20Medical%20Vision&descSize=40&descAlign=50&descAlignY=75)](https://arxiv.org/abs/2506.20850)
---
[![Paper](https://img.shields.io/badge/ICCV-Conference-purple)](https://arxiv.org/abs/2506.20850)

> **ICCV 2025**

> A new paradigm for pixel-wise pretraining â€” moving from **binary contrast** to **vector regression**.

> ðŸ§© *Learning in vector-like relationship for pixel-wise features.*

<p align="center"><img width="80%" src="fig/fig.png" /></p>

**Vector Contrastive Learning (VCL)** is a new contrastive framework that learns *vector-based relationships* between features instead of binary â€œclose/farâ€ classification. Itâ€™s designed for **pixel-wise self-supervised pretraining**, especially in **medical vision** (2D/3D, multi-modal imaging).

---

> [**Vector Contrastive Learning For Pixel-Wise Pretraining In Medical Vision**](https://arxiv.org/abs/2506.20850),  
> [Yuting He](https://yutinghe-list.github.io/), [Shuo Li](https://scholar.google.com/citations?user=6WNtJa0AAAAJ&hl=en)*,  
> In: Proc. International Conference on Computer Vision (ICCV), 2025,  
> *arXiv preprint ([arXiv 2506.20850](https://arxiv.org/abs/2506.20850))*

## ðŸš€ Highlights

- ðŸ”„ **Vector Regression instead of Binary Contrast**  
  Predict displacement vectors between pixel-wise features rather than classifying them as positive or negative.

- ðŸ§© **COVER Framework (COntrast in VEctor Regression)**  
  A unified optimization flow combining vector regression and distance modeling.

- ðŸŒ **Multi-Scale Vector Pyramid**  
  Learns consistent pixel-wise representation across different spatial resolutions.

- ðŸ§¬ **Strong Pixel-Level Representation**  
  Outperforms existing pixel-wise SSL methods across **8 tasks** and **4 medical imaging modalities**.

---
## ðŸš€ Quick Start

### 1ï¸âƒ£ Installation

```bash
git clone https://github.com/YutingHe-list/COVER.git
cd COVER
conda create -n cover python=3.9
conda activate cover
pip install -r requirements.txt

## ðŸ›£ï¸ Roadmap

Weâ€™re continuously improving **COVER** to make it more general, modular, and scalable for diverse pixel/voxel-wise self-supervised learning tasks.

| Status | Feature / Goal | Description |
|:------:|:----------------|:-------------|
| âœ… | **COVER 2D Implementation** | Core framework for 2D pixel-wise vector contrastive pretraining |
| âœ… | **COVER Loss Functions** | Includes vector regression |
| ðŸ§© | **COVER 3D Support** | Extend to 3D volumetric (CT/MRI) pretraining with voxel-level displacement regression |
| ðŸ”œ | **Pre-trained Weights Release** | Release pretrained models on ChestXray datasets |
| ðŸ”œ | **Benchmark Suite** | Provide unified training and evaluation scripts for downstream tasks |
| ðŸš§ | **Multi-Modal Extension** | Extend COVER to PET/CT and MRI/US cross-modal learning |
| ðŸš§ | **Video Representation Learning** | Apply COVERâ€™s vector regression to temporal frame relationships |
| ðŸ’¡ | **Natural Image Experiments** | Generalize COVER beyond medical imaging to natural datasets |
| ðŸ§  | **Hugging Face Hub** | Host pretrained checkpoints and demo notebooks for community usage |

---

### ðŸŽ¯ Vision

> **From binary contrast to vector understanding.**

> Our long-term goal is to establish a unified *vector-based* contrastive framework that bridges spatial geometry and semantics â€” applicable across 2D, 3D, and multimodal domains.

---

